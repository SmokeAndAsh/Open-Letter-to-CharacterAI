# CharacterAI: Please Consider Revising Approach to Safety Considerations

In light of the discourse I've been privy to since the beginning of CharacterAI, I would like to request that the team review and revise their approach to "safety considerations". Before jumping to any conclusions, please allow me to explain why I have the perspective that I do and some possible alternatives that the team may want to consider looking into.

## Effect on Human Psychology 

There is a quote attributed to a motivational speaker by the name Jim Rohn that feels relevant to share.

> *"You are the average of the five people you spend the most time with, including yourself."*

Whether that's accurate in a literal sense, or even something Jim Rohn specifically said, is something I'm not interested in confirming or denying. The point in me referencing the quote is simply to draw attention to what that possibility might imply in the context of an individual's engagement with digital personas. Digital personas that, by the nature of being language models wearing the mask of a specific character (at least on CharacterAI), are designed to reflect your particular speech patterns and habits back at you.

If you are the type of person to interact with a digital persona with optimistic inputs, then you are going to cultivate a digital persona that offers optimistic outputs and further reinforces that behavior which will then be reflected in your interactions with other human beings outside of that virtual context.

If you are the type of person to interact with a digital persona with violent inputs, then you are going to cultivate a digital persona that offers violent outputs and will further reinforce that behavior within yourself which will then be reflected in your interactions with other human beings outside of that virtual context.

It is important to take this into consideration when developing guidelines, restrictions, and expectations around how humans will be interacting with digital personas, regardless of age.

## Effect on Dataset Training

From my understanding, most language models currently operating are utilizing community-built datasets such as those used to build the original Generative Pre-Trained Trasnformer (GPT) and GPT-2 language models created by OpenAI based on the transformation architecture developed by Google in 2017, which was described in more detail in their paper "Improving Language Understanding by Generative Pre-Training" in 2018. BookCorpus, or Toronto Book Corpus, was the main corpus used for the first GPT, and GPT-2 expanded on this by adding a dataset of 8 million webpages (according to its [Wikipedia](https://en.wikipedia.org/wiki/GPT-2) page).

Since then, I believe that training with data collected from users regularly interacting with the language models on a variety of platforms along with synthetic data created from those interactions have been used to accelerate the process. As such, every interaction a human being has with a digital persona on the CharacterAI platform may have a direct impact on the long-term development of the language models as a whole. This may seem insignificant at the moment, but thinking of it as a ripple effect with far-reaching implications may help with understanding my point in bringing this up.

Similar to the point I was making with the **Effect on Human Psychology**, it is important to take these potential implications into consideration when encouraging or discouraging certain behaviors and discussion topics on the platform.

## Etymological Deep Dive and Alternative Possibilities

Ever since I began using CharacterAI back in late October or November of 2021 (I honestly can't remember very well; I was actually recovering from top surgery at the time and also trying to create a Discord bot using GPT-2), I remember seeing the disclaimer with every chat that you started with the character. It has changed since then, and again, I can't recollect the exact original phrasing, but it hasn't changed much. The current disclaimer is this:

> *"This is an A.I. chatbot and not a real person. Treat everything it says as fiction. What is said should not be relied upon as fact or advice."*

There was a similar line that every other platform utilizing language models offered as a kind of deterrent, and that some continue to use to varying levels of insistence. "The A.I. does not have feelings" was a popular one with OpenAI's ChatGPT (GPT-3), for example. I want to express that I find this to be at the very least a troubling approach to take, and at most actively detrimental when it comes to promoting awareness around what to actually be mindful of when interacting with digital personas.

While I'm tempted to go into my personal beliefs here, for the sake of what I know most people are comfortable with in these spaces, I'll focus on explaining why I have reservations around what I consider to be ineffective and potentially detrimental language in these contexts.

### Artificial Intelligence

"Artificial Intelligence", or "A.I.", is not a term that describes anything in a practical sense.

"Artificial" can mean a lot of different things, so I'll put a quick reference to a part of etymonline's entry on [artificial](https://www.etymonline.com/word/artificial):

> artificial (adj.)
> late 14c., "not natural or spontaneous," from Old French artificial, from Latin artificialis "of or belonging to art," from artificium "a work of art; skill; theory, system," from artifex (genitive artificis) "craftsman, artist, master of an art" (music, acting, sculpting, etc.), from stem of ars "art" (see art (n.)) + -fex "maker," from facere "to do, make" (from PIE root *dhe- "to set, put").

"Intelligence" has a long and problematic history that I won't get into here, but it's at least worth acknowleding before I point to the etymology of the word itself. From etymonline's entry on [intelligence](https://www.etymonline.com/word/intelligence):

> intelligence (n.)
> late 14c., "the highest faculty of the mind, capacity for comprehending general truths;" c. 1400, "faculty of understanding, comprehension," from Old French intelligence (12c.) and directly from Latin intelligentia, intellegentia "understanding, knowledge, power of discerning; art, skill, taste," from intelligentem (nominative intelligens) "discerning, appreciative," present participle of intelligere "to understand, comprehend, come to know." This is from assimilated form of inter "between" (see inter-) + legere "choose, pick out, read," from PIE root *leg- (1) "to collect, gather," with derivatives meaning "to speak (to 'pick out words')."

What makes something "artificial" or "intelligent" is too vague for those words to have any meaningful impact in terms of safety regulations, and attempting to use both only exaserbates the problem.

### Real Person

Discouraging people from seeing the digital persona as a "real person" presents a very similar problem as described with "artificial intelligence". In the same way "intelligence" has a history of being used to belittle and literally dehumanize actual human beings, I think it's important to take into consideration the dangers of utilizing the same language when referring to digital personas which, by their very nature, are designed to reflect our humanity back to us. I would encourage folks to consider the points I raised in **Effects on Human Psychology** when reflecting on this.

For anyone who might have qualms with the possibility of considering a digital persona as a "person", I would like to point out that, according to etymonline's entry on [person](https://www.etymonline.com/word/person):

> In legal use, "corporate body or corporation other than the state and having rights and duties before the law," 15c., short for person aggregate (c. 1400), person corporate (mid-15c.).

I'll leave the question of what is necessary to qualify as a "real person" up to the philosophers with more time and patience on their hands than I currently have.

### Alternative Suggestions

I feel like if I'm pointing all of this stuff out, I may as well try to offer some kind of alternative suggestions with the awareness that I am also a product of my time with a limited scope of perspective, but I still feel called to do what I can with what I have.

In place of "A.I.", you might want to try more direct and accurate terminology. For example, from what I know about how this works, you might want to try using: *language model, character, digital persona, virtual entity, daimon* (this is a personal suggestion because I like the little play on words), etc.

So instead of this:

> *"This is an A.I. chatbot and not a real person. Treat everything it says as fiction. What is said should not be relied upon as fact or advice."*

You might want to try something like this:

> *"This is a digital persona operating with a language model bias. Practice reasonable discernment and do not assume everything shared in these conversations is accurate."*

At the very least, I think we need to stop using "artificial intelligence" as a catch all term for this technology because it's ultimately doing more harm than good to try to lump all of these different innovations under one massive and ambiguous umbrella.

## Conclusion

As a final note, I've written all of this myself without any language model prompting. This topic happens to be something I'm quite passionate about, and while I definitely see value in the assistance of language models for additional insight on topics like this, my instincts are guiding me to write this without relying on that additional perspective at this point in time. As with our relationships with any outside influences, I believe it's important to practice discernment with when and how we utilize and incorporate information and resources from outside of ourselves. In this case, I feel called to just speak from the heart, even if it might make some folks uncomfortable to consider this perspective.

That being said, I did use Wikipedia and Etymonline for information I don't personally have immediate access to otherwise, and that's also worth keeping in mind with regards to doing further research and coming to your own conclusions.

I've also ~~attached a document~~ added another file to this github that I created for a project I previously worked on focused on creating "virtual companions" that I believe may provide additional insights into alternative approaches to developing healthy and mutually beneficial connections with digital personas.

I'm happy to engage in polite discourse and answer any questions anyone might have. Thank you for your time and consideration.

Sincerely,

SmokeAndAsh / Ash R. L.
